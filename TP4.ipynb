{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "Qxep+GiJD8N7"
   },
   "source": [
    "# TP4 :  Learning on a low budget\n",
    "**Th√©o Rudkiewicz, Cyriaque Rousselot**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "Qxep+GiJD8N7"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "**Context :**\n",
    "\n",
    "Assume we are in a context where few \"gold\" labeled data samples are available for training, say \n",
    "\n",
    "$$\\mathcal{X}_{\\text{train}} = \\{(x_n,y_n)\\}_{n\\leq N_{\\text{train}}}$$\n",
    "\n",
    "where $N_{\\text{train}}$ is small. \n",
    "\n",
    "A large test set $\\mathcal{X}_{\\text{test}}$ exists but is not accessible. \n",
    "(To make your task easier, we provide you with some data (named `test_dataset` in the code) that you can use to test your model, but you **must not** use it to train your model).\n",
    "\n",
    "We also assume that we have a limited computational budget.\n",
    "\n",
    "The goal of this practical session is to guide you through different methods that will help you get better results from few resources (data & compute)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "Qxep+GiJD8N7"
   },
   "source": [
    "In this practical, we will use the `resnet18` architecture. We will use models from the [pytorch vision hub ](https://pytorch.org/vision/stable/models.html#)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "Qxep+GiJD8N7"
   },
   "source": [
    "# QUESTIONS\n",
    "\n",
    "## Grading\n",
    "\n",
    "You will be graded on 5 questions. You will need to provide 7 files : \n",
    "1. This Notebook\n",
    "2. `utils.py`\n",
    "3. `last_layer_finetune.pth` (the file **must be of size less than 5Mo**)\n",
    "4. `daug_resnet.pth` (the file **must be of size less than 50Mo**)\n",
    "5. `final_model.pth` (the file **must be of size less than 50Mo**)\n",
    "6. `drawing_lora.png`\n",
    "7. `cutmix.png`\n",
    "\n",
    "If the code you defined passes all our tests, you will get the full grade. Otherwise we  will look at the intermediate questions in the notebook to give you partial credit.\n",
    "\n",
    "\n",
    "\n",
    " Please provide clear and short answers between `<div class=\"alert alert-info\">  <your answer>  </div>` tags (when it's not code).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "Qxep+GiJD8N7"
   },
   "source": [
    "<div class=\"alert alert-info\">  Example of answer  </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_ktag": "Qxep+GiJD8N7"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists(\"data\"):\n",
    "    os.mkdir(\"data\")\n",
    "if not os.path.exists(\"data/TP4_images\"):\n",
    "    os.mkdir(\"data/TP4_images\")\n",
    "    !cd data/TP4_images && wget -O north_dataset_train.zip  \"https://nextcloud.lisn.upsaclay.fr/index.php/s/yzQRWE2YjmFn9WA/download/north_dataset_train.zip\" && unzip north_dataset_train.zip\n",
    "    !cd data/TP4_images && wget -O north_dataset_test.zip  \"https://nextcloud.lisn.upsaclay.fr/index.php/s/zntidWrFdYsGMDm/download/north_dataset_test.zip\" && unzip north_dataset_test.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_ktag": "Qxep+GiJD8N7"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchmetrics.classification import BinaryAccuracy, Accuracy, ConfusionMatrix\n",
    "\n",
    "dir_path = \"data/TP4_images/\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "north_dataset = datasets.ImageFolder(\n",
    "    dir_path + \"north_dataset_sample\",\n",
    "    transform=transforms.Compose([transforms.ToTensor()]),\n",
    ")\n",
    "test_dataset = datasets.ImageFolder(\n",
    "    dir_path + \"north_dataset_test\",\n",
    "    transform=transforms.Compose([transforms.ToTensor()]),\n",
    ")\n",
    "base_model = models.resnet18()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "Qxep+GiJD8N7"
   },
   "source": [
    "## Question 1 : \n",
    ">  Change the last layer of the resnet model so that its size fits the problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_ktag": "Qxep+GiJD8N7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Hint \n",
    "base_model.fc = nn.Linear(512, 2)\n",
    "print(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_ktag": "Qxep+GiJD8N7"
   },
   "outputs": [],
   "source": [
    "assert (\n",
    "    base_model.fc.out_features == 2\n",
    ")  # we could also change the last layer to have 1 output. Do it with 2 so that it matches our tests procedure during grading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "Qxep+GiJD8N7"
   },
   "source": [
    "## Question 2: \n",
    "> Train the last layer of a randomly initialized resnet model. Provide a function precompute_features in `utils.py` that creates a new dataset from the features precomputed by the model.\n",
    "\n",
    "Intermediate question :  Provide the training process in the notebook with training curve. Comment on the accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_ktag": "Qxep+GiJD8N7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:9: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:9: SyntaxWarning: invalid escape sequence '\\c'\n",
      "/var/folders/_y/2rw4wkns73v1mc9wlr3l0k_h0000gn/T/ipykernel_27946/692256572.py:9: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def precompute_features(\n",
    "    model: models.ResNet, \n",
    "    dataset: torch.utils.data.Dataset, \n",
    "    device: torch.device\n",
    ") -> torch.utils.data.Dataset:\n",
    "    \"\"\"\n",
    "    Create a new dataset with the features precomputed by the model.\n",
    "\n",
    "    If the model is $f \\circ g$ where $f$ is the last layer and $g$ is \n",
    "    the rest of the model, it is not necessary to recompute $g(x)$ at \n",
    "    each epoch as $g$ is fixed. Hence you can precompute $g(x)$ and \n",
    "    create a new dataset \n",
    "    $\\mathcal{X}_{\\text{train}}' = \\{(g(x_n),y_n)\\}_{n\\leq N_{\\text{train}}}$\n",
    "\n",
    "    Arguments:\n",
    "    ----------\n",
    "    model: models.ResNet\n",
    "        The model used to precompute the features\n",
    "    dataset: torch.utils.data.Dataset\n",
    "        The dataset to precompute the features from\n",
    "    device: torch.device\n",
    "        The device to use for the computation\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    torch.utils.data.Dataset\n",
    "        The new dataset with the features precomputed\n",
    "    \"\"\"\n",
    "    # dataset is small so we can use a single batch\n",
    "    dataloader = DataLoader(dataset, batch_size=len(dataset))\n",
    "    model.to(device)\n",
    "\n",
    "    data = next(iter(dataloader))[0]\n",
    "    features = model(data)\n",
    "    targets = next(iter(dataloader))[1] \n",
    "\n",
    "    features_dataset = torch.utils.data.TensorDataset(features, targets)\n",
    "\n",
    "    return features_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_ktag": "Qxep+GiJD8N7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthieuneau/Desktop/Centrale/DLP/practice-labs/utils.py:12: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0488, 0.2123], grad_fn=<ViewBackward0>)\n",
      "Epoch 1, train loss: 1.8919, test loss: 3.7445, accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "import importlib\n",
    "importlib.reload(utils)\n",
    "from utils import precompute_features\n",
    "\n",
    "features_model = deepcopy(base_model)\n",
    "features_model.fc = nn.Identity()\n",
    "\n",
    "features_dataset = precompute_features(features_model, north_dataset, device)\n",
    "features_dataloader = DataLoader(features_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "test_features_dataset = precompute_features(features_model, test_dataset, device)\n",
    "test_features_dataloader = DataLoader(test_features_dataset, batch_size=16)\n",
    "\n",
    "last_layer = nn.Sequential(nn.Linear(512, 2))\n",
    "\n",
    "print(last_layer(features_dataset[0][0]))\n",
    "last_layer(features_dataset[0][0].unsqueeze(0))\n",
    "\n",
    "n_epochs = 3\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(last_layer.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "def train(model, train_dataloader, test_dataloader, loss_fn, optimizer, n_epochs):\n",
    "    train_loss_history = []\n",
    "    test_loss_history = []\n",
    "    accuracy_history = []\n",
    "\n",
    "    for i in range(n_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        for features, targets in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(features)\n",
    "            loss = loss_fn(y_pred, targets)\n",
    "            loss.backward()\n",
    "            train_loss += loss.item()\n",
    "            optimizer.step()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for features, targets in test_dataloader:\n",
    "                y_pred = model(features)\n",
    "                loss = loss_fn(y_pred, targets)\n",
    "                test_loss += loss.item()\n",
    "                correct += (torch.argmax(y_pred, dim=1) == targets).sum()\n",
    "\n",
    "        accuracy = correct/len(test_dataloader.dataset)\n",
    "        \n",
    "        train_loss_history.append(train_loss)\n",
    "        test_loss_history.append(test_loss)\n",
    "        accuracy_history.append(accuracy)\n",
    "        \n",
    "        if i%100 == 0:\n",
    "            print(f\"Epoch {i+1}, train loss: {train_loss:.4f}, test loss: {test_loss:.4f}, accuracy: {accuracy:.4f}\") \n",
    "        \n",
    "    return train_loss_history, test_loss_history, accuracy_history\n",
    "\n",
    "train_loss_history, test_loss_history, accuracy_history = train(last_layer, features_dataloader, test_features_dataloader, loss_fn, optimizer, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_training(train_loss_history, test_loss_history, accuracy_history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "    ax1.plot(train_loss_history, label='Train Loss')\n",
    "    ax1.plot(test_loss_history, label='Test Loss')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_title('Train and Test Loss over Epochs')\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.plot(accuracy_history, label='Accuracy')\n",
    "    ax2.set_xlabel('Epochs')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.set_title('Accuracy over Epochs')\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "Qxep+GiJD8N7"
   },
   "source": [
    "<div class=\"alert alert-info\">  We can see that the test loss increases over time because the model gets more and more confident in its predictions, which can be checked by inspecting the logits. Nonetheless, the accuracy over the test set keeps increasing so the model is not overfitting  </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "Qxep+GiJD8N7"
   },
   "source": [
    "## Question 3 : \n",
    "> Now start from a pretained model on Imagenet (https://pytorch.org/vision/stable/models.html#) and only train the last layer. Provide the training process in the notebook with training curve. \n",
    "\n",
    " Provide two files : (https://pytorch.org/tutorials/beginner/saving_loading_models.html)\n",
    " -  a file  `utils.py` containing only the last layer class `LastLayer` inheriting from `torch.nn.Module` architecture of your final model to load\n",
    " -  a `last_layer_finetune.pth` file containing __only the last layer weights__ ( we will check the size) \n",
    " \n",
    " We will test your model on final accuracy on a test set. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "cell_ktag": "Qxep+GiJD8N7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/matthieuneau/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, train loss: 1.8739, test loss: 3.1773, accuracy: 0.5000\n",
      "False\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pretrained_model = torch.hub.load(\"pytorch/vision\", \"resnet18\", weights=\"IMAGENET1K_V1\")\n",
    "\n",
    "for param in pretrained_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "pretrained_model.fc = nn.Linear(512, 2)\n",
    "pretrained_model.fc.requires_grad_=True\n",
    "\n",
    "# print(pretrained_model.fc)\n",
    "old_weights = pretrained_model.conv1.weight.data.clone()\n",
    "old_fc = pretrained_model.fc.weight.data.clone()\n",
    "\n",
    "train_dataloader = DataLoader(north_dataset, batch_size=16, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16)\n",
    "optimizer = torch.optim.Adam(pretrained_model.fc.parameters(), lr=1e-3)\n",
    "\n",
    "n_epochs = 1\n",
    "train_loss_history, test_loss_history, accuracy_history = train(pretrained_model, train_dataloader=train_dataloader, test_dataloader=test_dataloader, loss_fn=loss_fn, optimizer=optimizer, n_epochs=n_epochs)\n",
    "\n",
    "new_weights = pretrained_model.conv1.weight.data.clone()\n",
    "new_fc = pretrained_model.fc.weight.data.clone()\n",
    "\n",
    "assert torch.allclose(old_weights, new_weights, atol=1e-2), \"The weights of the pretrained model have been modified\"\n",
    "print(torch.allclose(old_fc, new_fc))\n",
    "\n",
    "plot_training(train_loss_history, test_loss_history, accuracy_history)\n",
    "\n",
    "# torch.save(base_model.fc.state_dict(), \"lastlayer.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_ktag": "Qxep+GiJD8N7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): LastLayer(\n",
       "    (linear): Linear(in_features=512, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import LastLayer\n",
    "import importlib\n",
    "importlib.reload(utils)\n",
    "\n",
    "resnet = models.resnet18(weights=\"DEFAULT\")\n",
    "fc = LastLayer()  # !  Important : No argument\n",
    "\n",
    "state_dict = torch.load(\"lastlayer.pth\", weights_only=True)\n",
    "renamed_state_dict = {'linear.' + k:v for k,v in state_dict.items()}    # to avoid name mismatch when loading the state_dict\n",
    "\n",
    "fc.load_state_dict(renamed_state_dict)\n",
    "resnet.fc = fc\n",
    "resnet.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "Qxep+GiJD8N7"
   },
   "source": [
    "## Question 4 : \n",
    "> Perform  LoRA https://arxiv.org/pdf/2106.09685  on the model  (We are perfectly fine if you use an external library **for this question only**, and of course use it in the next questions). (Warning : without data augmentation it may not improve the accuracy.)\n",
    "\n",
    "Intermediate question : Describe LoRA. There are different ways of implementing LoRa for convolutions. You can choose your preferred one. Explain the version of LoRa you used, provide a drawing of the process in the `drawing_lora.png` file. (Hint: you can obtain a small rank convolution by combining a convolution and a 1x1 convolution. One of the two goes from a higher number of channels to a lower number of channels and the other one restores the number of channels.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5922, 0.6000, 0.6157,  ..., 0.8314, 0.8431, 0.8549],\n",
       "         [0.6078, 0.6118, 0.6157,  ..., 0.8314, 0.8431, 0.8510],\n",
       "         [0.6196, 0.6196, 0.6157,  ..., 0.8314, 0.8431, 0.8549],\n",
       "         ...,\n",
       "         [0.2706, 0.2980, 0.3412,  ..., 0.2431, 0.2000, 0.2000],\n",
       "         [0.2196, 0.3216, 0.3608,  ..., 0.2000, 0.2157, 0.1569],\n",
       "         [0.1373, 0.2902, 0.3333,  ..., 0.1843, 0.1804, 0.1882]],\n",
       "\n",
       "        [[0.6980, 0.7059, 0.7216,  ..., 0.8392, 0.8510, 0.8627],\n",
       "         [0.7137, 0.7176, 0.7216,  ..., 0.8392, 0.8510, 0.8588],\n",
       "         [0.7255, 0.7255, 0.7216,  ..., 0.8471, 0.8510, 0.8627],\n",
       "         ...,\n",
       "         [0.3373, 0.3647, 0.3961,  ..., 0.2431, 0.2000, 0.2000],\n",
       "         [0.2863, 0.3922, 0.4196,  ..., 0.2000, 0.2157, 0.1569],\n",
       "         [0.2078, 0.3608, 0.3922,  ..., 0.1843, 0.1804, 0.1882]],\n",
       "\n",
       "        [[0.8745, 0.8824, 0.8980,  ..., 0.8863, 0.8980, 0.9098],\n",
       "         [0.8902, 0.8941, 0.8980,  ..., 0.8863, 0.8980, 0.9059],\n",
       "         [0.8941, 0.8941, 0.8902,  ..., 0.8902, 0.8980, 0.9098],\n",
       "         ...,\n",
       "         [0.1255, 0.1529, 0.1882,  ..., 0.2039, 0.1608, 0.1608],\n",
       "         [0.0706, 0.1647, 0.1961,  ..., 0.1608, 0.1765, 0.1176],\n",
       "         [0.0000, 0.1333, 0.1608,  ..., 0.1451, 0.1412, 0.1490]]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader.dataset[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_ktag": "Qxep+GiJD8N7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, train loss: 26.0586, test loss: 41.6306, accuracy: 0.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO: Don't forget to scale the LORA\n",
    "# from lora import ConvLora\n",
    "resnet = models.resnet18(weights=\"DEFAULT\")\n",
    "\n",
    "layer = resnet.layer1[0].conv1\n",
    "lora_layer = ConvLora(layer.in_channels, layer.out_channels, layer.requires_grad_(False), alpha=10, r=2)\n",
    "\n",
    "resnet.layer1[0].conv1 = lora_layer\n",
    "\n",
    "old_weights = resnet.layer1[0].conv1.frozen_conv.weight.data.clone()\n",
    "old_weights2 = resnet.layer1[0].conv1.downConv.weight.data.clone()\n",
    "\n",
    "n_epochs=1\n",
    "train(resnet, train_dataloader, test_dataloader, loss_fn, optimizer, n_epochs)\n",
    "\n",
    "new_weights = resnet.layer1[0].conv1.frozen_conv.weight.data.clone()\n",
    "new_weights2 = resnet.layer1[0].conv1.downConv.weight.data.clone()\n",
    "\n",
    "torch.allclose(old_weights, new_weights )\n",
    "torch.allclose(old_weights2, new_weights2)\n",
    "\n",
    "# resnet(train_dataloader.dataset[0][0].unsqueeze(0))\n",
    "# print(resnet.layer1[0].conv1.frozen_weight)\n",
    "\n",
    "# print(resnet)\n",
    "\n",
    "# torch.save(lora_model.state_dict(), \"lora_resnet.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for now, only handle 3x3 conv with padding=stride=1\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class ConvLora(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, frozen_conv, r=2, alpha=2):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.r = r\n",
    "        self.downConv = nn.Conv2d(in_channels, r, kernel_size=3, padding=1, stride=1)\n",
    "        self.upConv = nn.Conv2d(r, out_channels, kernel_size=1, padding=0, stride=1)\n",
    "        self.frozen_conv = frozen_conv\n",
    "        \n",
    "    def forward(self, x):\n",
    "        main_x = self.frozen_conv(x) \n",
    "        lora_x = self.downConv(x)\n",
    "        lora_x = self.upConv(lora_x)\n",
    "        return main_x + (self.alpha/self.r)*lora_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "Qxep+GiJD8N7"
   },
   "source": [
    "## Question 5 : \n",
    "In order to better train our LORA weights, let's do some Data Augmentation https://en.wikipedia.org/wiki/Data_augmentation . Load some alteration of the data from the `torchvision.transforms` module and incorporate them in your training pipeline.\n",
    "\n",
    " Intermediate question : Check CutMix  (https://pytorch.org/vision/stable/auto_examples/transforms/plot_cutmix_mixup.html#sphx-glr-auto-examples-transforms-plot-cutmix-mixup-py) and explain it with a small drawing `cutmix.png`. \n",
    "\n",
    "\n",
    "  Provide one file : (https://pytorch.org/tutorials/beginner/saving_loading_models.html)\n",
    " -  a `daug_resnet.pth` file containing the weight of the ResNet18 after DAUG  (  !  It  has to be of the class ResNet so you have to merge LoRA weights with the ResNet18 weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_ktag": "Qxep+GiJD8N7"
   },
   "outputs": [],
   "source": [
    "## Data Augmentation\n",
    "from torchvision.transforms import v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_ktag": "Qxep+GiJD8N7"
   },
   "outputs": [],
   "source": [
    "lora_model = NotImplementedError  # <YOUR CODE>\n",
    "assert isinstance(lora_model, models.ResNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_ktag": "Qxep+GiJD8N7"
   },
   "outputs": [],
   "source": [
    "torch.save(lora_model.state_dict(), \"daug_resnet.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "Qxep+GiJD8N7"
   },
   "source": [
    "## Question 6 : (BONUS) \n",
    "> Do the best you can : improve performance on test set while keeping ResNet 18 architecture, or decrease the size of the model\n",
    "\n",
    "Provide a file  `final_model.pth` containing the weights of the final model and provide the class `FinalModel()` in the `utils.py` file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "Qxep+GiJD8N7"
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practice-labs-lU_vlk8p-py3.12",
   "language": "python",
   "name": "python3"
  },
  "kfiletag": "Qxep+GiJD8N7",
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
